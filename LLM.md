Large Language Models - 
    Architecture - Transformers: LLMs are primarily built using transformer architecture. This is a deep learning model that use self-attention mechanism to process sequential data(like text) efficiently. and probabilistic modeling to understand and generate text.
